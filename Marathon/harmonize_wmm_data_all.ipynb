{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>\n",
    "<hr>\n",
    "<h1>Harmonisierung der geparsten Daten:</h1>\n",
    "<h2>1. Berlin<h2>\n",
    "<h2>2. Chicago</h2>\n",
    "<h2>3. London</h2>\n",
    "<h2>4. New York</h2>\n",
    "<h2>5. Tokyo</h2>\n",
    "<hr>\n",
    "<hr>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Hauptverzeichnis setzen\n",
    "main_data_path = '/home/paul/python_projects/masterthesis/'\n",
    "# Das Hauptverzeichnis muss folgende Unterverzeichnisse mit den Daten enthalten (ansonsten müssen diese im Code angepasst werden):\n",
    "# /Berlin/\n",
    "# /Chicago/\n",
    "# /London/\n",
    "# /NYC/\n",
    "# /Tokyo/\n",
    "# /wmm_data/"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>1. Berlin-Marathon:</h1>\n",
    "<hr>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Daten einlesen\n",
    "df_berlin_data_csv = pd.read_csv(filepath_or_buffer=main_data_path +'Berlin/daten_wmm_berlin_all.csv',\n",
    "    header=0, sep=';',\n",
    "    decimal='.',\n",
    "    names=['Jahr', 'Platz','Vorname', 'Nachname', 'NAT', 'SN', 'Verein','Geschlecht','Netto', 'Brutto','5KM','10KM','15KM','20KM','HM','25KM','30KM','35KM','40KM']\n",
    ")\n",
    "\n",
    "df_berlin_data_csv.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Nicht benötigte Spalten entfernen\n",
    "df_berlin_data = df_berlin_data_csv.drop(columns=['NAT','SN','Verein','Brutto'])\n",
    "\n",
    "# Spalten hinzufügen\n",
    "df_berlin_data['Datum'] = None\n",
    "df_berlin_data['Startzeit'] = None\n",
    "df_berlin_data['Ort'] = 'Berlin'\n",
    "\n",
    "# Datum für für das jeweilige Jahr eintragen\n",
    "df_berlin_data['Datum'].mask(df_berlin_data['Jahr'] == 2019,'29.09.2019',inplace=True)\n",
    "df_berlin_data['Datum'].mask(df_berlin_data['Jahr'] == 2018,'16.09.2018',inplace=True)\n",
    "df_berlin_data['Datum'].mask(df_berlin_data['Jahr'] == 2017,'24.09.2017',inplace=True)\n",
    "df_berlin_data['Datum'].mask(df_berlin_data['Jahr'] == 2016,'25.09.2016',inplace=True)\n",
    "df_berlin_data['Datum'].mask(df_berlin_data['Jahr'] == 2015,'27.09.2015',inplace=True)\n",
    "df_berlin_data['Datum'].mask(df_berlin_data['Jahr'] == 2014,'28.09.2014',inplace=True)\n",
    "df_berlin_data['Datum'].mask(df_berlin_data['Jahr'] == 2013,'29.09.2013',inplace=True)\n",
    "df_berlin_data['Datum'].mask(df_berlin_data['Jahr'] == 2012,'30.09.2012',inplace=True)\n",
    "df_berlin_data['Datum'].mask(df_berlin_data['Jahr'] == 2011,'25.09.2011',inplace=True)\n",
    "df_berlin_data['Datum'].mask(df_berlin_data['Jahr'] == 2010,'26.09.2010',inplace=True)\n",
    "df_berlin_data['Datum'].mask(df_berlin_data['Jahr'] == 2009,'20.09.2009',inplace=True)\n",
    "df_berlin_data['Datum'].mask(df_berlin_data['Jahr'] == 2008,'28.09.2008',inplace=True)\n",
    "df_berlin_data['Datum'].mask(df_berlin_data['Jahr'] == 2007,'30.09.2007',inplace=True)\n",
    "\n",
    "# Spalten umbenennen\n",
    "df_berlin_data = df_berlin_data.rename(\n",
    "    columns={'Netto':'T_KM_FN','5KM':'T_KM_5','10KM':'T_KM_10','15KM':'T_KM_15','20KM':'T_KM_20','HM':'T_KM_HM','25KM':'T_KM_25','30KM':'T_KM_30','35KM':'T_KM_35','40KM':'T_KM_40'})\n",
    "\n",
    "# Spalten umsortieren\n",
    "df_berlin_data = df_berlin_data[['Jahr','Ort','Geschlecht','Vorname','Nachname','Platz','Datum','Startzeit','T_KM_FN','T_KM_5','T_KM_10','T_KM_15','T_KM_20','T_KM_HM','T_KM_25','T_KM_30','T_KM_35','T_KM_40']]\n",
    "df_berlin_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>\n",
    "<h1>2. Chicago-Marathon:</h1>\n",
    "<hr>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# Temporäres Dateframe erzeugen\n",
    "df_chicago_data_csv = pd.DataFrame(pd.DataFrame(\n",
    "    columns=[\n",
    "        'Jahr','Ges', 'Name', 'Age_Group', 'Runner_Number', 'Place_Gender', 'Place_Age_Group','Place_Overall','Start_Time_of_day','Finish_Time','5K_Time','5K_Diff','5K_min_km','5K_kmh'\n",
    "        ,'10K_Time','10K_Diff','10K_min_km','10K_kmh','15K_Time','15K_Diff','15K_min_km','15K_kmh','20K_Time','20K_Diff','20K_min_km','20K_kmh','HK_Time','HK_Diff','HK_min_km','HK_kmh'\n",
    "        ,'25K_Time','25K_Diff','25K_min_km','25K_kmh','30K_Time','30K_Diff','30K_min_km','30K_kmh','35K_Time','35K_Diff','35K_min_km','35K_kmh','40K_Time','40K_Diff','40K_min_km','40K_kmh'\n",
    "        ,'FK_Time','FK_Diff','FK_min_km','FK_kmh'\n",
    "        ])\n",
    "    ,dtype=str)\n",
    "\n",
    "# Daten einlesen\n",
    "for year in range(2007,2020):\n",
    "        file_path = main_data_path + 'Chicago/daten_wmm_chicago_' + str(year) + '.csv'\n",
    "        df_chicago_data_csv_temp = pd.read_csv(filepath_or_buffer=file_path,\n",
    "                header=0, sep=';',decimal='.'\n",
    "                ,names=[\n",
    "                'Jahr','Ges', 'Name', 'Age_Group', 'Runner_Number', 'Place_Gender', 'Place_Age_Group','Place_Overall','Start_Time_of_day','Finish_Time','5K_Time','5K_Diff','5K_min_km','5K_kmh'\n",
    "                ,'10K_Time','10K_Diff','10K_min_km','10K_kmh','15K_Time','15K_Diff','15K_min_km','15K_kmh','20K_Time','20K_Diff','20K_min_km','20K_kmh','HK_Time','HK_Diff','HK_min_km','HK_kmh'\n",
    "                ,'25K_Time','25K_Diff','25K_min_km','25K_kmh','30K_Time','30K_Diff','30K_min_km','30K_kmh','35K_Time','35K_Diff','35K_min_km','35K_kmh','40K_Time','40K_Diff','40K_min_km','40K_kmh'\n",
    "                ,'FK_Time','FK_Diff','FK_min_km','FK_kmh'\n",
    "                ]\n",
    "        )\n",
    "        df_chicago_data_csv = df_chicago_data_csv.append(df_chicago_data_csv_temp, ignore_index=True)\n",
    "\n",
    "df_chicago_data_csv.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Nicht benötigte Spalten entfernen\n",
    "df_chicago_data = df_chicago_data_csv.drop(\n",
    "    columns=['Age_Group','Runner_Number','Place_Age_Group','Finish_Time','Place_Overall','5K_Diff','5K_min_km','5K_kmh','10K_Diff','10K_min_km','10K_kmh'\n",
    "            ,'15K_Diff','15K_min_km','15K_kmh','20K_Diff','20K_min_km','20K_kmh','HK_Diff','HK_min_km','HK_kmh','25K_Diff','25K_min_km','25K_kmh'\n",
    "            ,'30K_Diff','30K_min_km','30K_kmh','35K_Diff','35K_min_km','35K_kmh','40K_Diff','40K_min_km','40K_kmh','FK_Diff','FK_min_km','FK_kmh'\n",
    "    ])\n",
    "\n",
    "# Spalten hinzufügen\n",
    "df_chicago_data['Datum'] = None\n",
    "df_chicago_data['Nachname'] = None\n",
    "df_chicago_data['Ort'] = 'Chicago'\n",
    "\n",
    "# Datum für für das jeweilige Jahr eintragen\n",
    "df_chicago_data['Datum'].mask(df_chicago_data['Jahr'] == 2019,'13.10.2019',inplace=True)\n",
    "df_chicago_data['Datum'].mask(df_chicago_data['Jahr'] == 2018,'07.10.2018',inplace=True)\n",
    "df_chicago_data['Datum'].mask(df_chicago_data['Jahr'] == 2017,'08.10.2017',inplace=True)\n",
    "df_chicago_data['Datum'].mask(df_chicago_data['Jahr'] == 2016,'09.10.2016',inplace=True)\n",
    "df_chicago_data['Datum'].mask(df_chicago_data['Jahr'] == 2015,'11.10.2015',inplace=True)\n",
    "df_chicago_data['Datum'].mask(df_chicago_data['Jahr'] == 2014,'12.10.2014',inplace=True)\n",
    "df_chicago_data['Datum'].mask(df_chicago_data['Jahr'] == 2013,'13.10.2013',inplace=True)\n",
    "df_chicago_data['Datum'].mask(df_chicago_data['Jahr'] == 2012,'07.10.2012',inplace=True)\n",
    "df_chicago_data['Datum'].mask(df_chicago_data['Jahr'] == 2011,'09.10.2011',inplace=True)\n",
    "df_chicago_data['Datum'].mask(df_chicago_data['Jahr'] == 2010,'10.10.2010',inplace=True)\n",
    "df_chicago_data['Datum'].mask(df_chicago_data['Jahr'] == 2009,'11.10.2009',inplace=True)\n",
    "df_chicago_data['Datum'].mask(df_chicago_data['Jahr'] == 2008,'12.10.2008',inplace=True)\n",
    "df_chicago_data['Datum'].mask(df_chicago_data['Jahr'] == 2007,'07.10.2007',inplace=True)\n",
    "\n",
    "# Spalten umbenennen\n",
    "df_chicago_data = df_chicago_data.rename(\n",
    "    columns={'Ges':'Geschlecht','Place_Gender':'Platz','FK_Time':'T_KM_FN','Name':'Vorname','Start_Time_of_day' : 'Startzeit',\n",
    "    '5K_Time':'T_KM_5','10K_Time':'T_KM_10','15K_Time':'T_KM_15','20K_Time':'T_KM_20','HK_Time':'T_KM_HM','25K_Time':'T_KM_25','30K_Time':'T_KM_30','35K_Time':'T_KM_35','40K_Time':'T_KM_40'})\n",
    "\n",
    "# Spalten umsortieren\n",
    "df_chicago_data = df_chicago_data[['Jahr','Ort','Geschlecht','Vorname','Nachname','Platz','Datum','Startzeit','T_KM_FN','T_KM_5','T_KM_10','T_KM_15','T_KM_20','T_KM_HM','T_KM_25','T_KM_30','T_KM_35','T_KM_40']]\n",
    "\n",
    "# Inhalt aus der ursprünglichen Spalte Name in Vorname und Nachname trennen\n",
    "for index, row in df_chicago_data.iterrows():\n",
    "    #print(row['Vorname'])\n",
    "    name_split_1 = row['Vorname'].split(',')\n",
    "    name_split_2 = name_split_1[1].split(' ')\n",
    "    name_split_2.pop(0)\n",
    "    name_split_2.pop(len(name_split_2)-1)\n",
    "    name_split_2 = ' '.join(name_split_2)\n",
    "    row['Vorname'] = name_split_2\n",
    "    row['Nachname'] = name_split_1[0]\n",
    "\n",
    "# Variable auf \"none\" setzen für spätere Verwendung\n",
    "name_split_1 = None\n",
    "name_split_2 = None\n",
    "\n",
    "df_chicago_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>\n",
    "<h1>3. London-Marathon:</h1>\n",
    "<hr>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Temporäres Dateframe erzeugen\n",
    "df_london_data_csv = pd.DataFrame(pd.DataFrame(\n",
    "    columns=[\n",
    "        'Jahr','Ges', 'Name','Club', 'Category', 'Runner_Number', 'Place_Gender', 'Place_Category','Place_Overall','Start_Time_of_day','Finish_Time', 'Race_Status','Last_Split'\n",
    "        ,'5K_Time_of_day','5K_Time','5K_Diff','5K_min_km','5K_kmh','10K_Time_of_day','10K_Time','10K_Diff','10K_min_km','10K_kmh','15K_Time_of_day','15K_Time','15K_Diff','15K_min_km','15K_kmh'\n",
    "        ,'20K_Time_of_day','20K_Time','20K_Diff','20K_min_km','20K_kmh','HK_Time_of_day','HK_Time','HK_Diff','HK_min_km','HK_kmh','25K_Time_of_day','25K_Time','25K_Diff','25K_min_km','25K_kmh'\n",
    "        ,'30K_Time_of_day','30K_Time','30K_Diff','30K_min_km','30K_kmh','35K_Time_of_day','35K_Time','35K_Diff','35K_min_km','35K_kmh','40K_Time_of_day','40K_Time','40K_Diff','40K_min_km','40K_kmh'\n",
    "        ,'FK_Time_of_day','FK_Time','FK_Diff','FK_min_km','FK_kmh'\n",
    "        ])\n",
    "    ,dtype=str)\n",
    "\n",
    "# Daten einlesen\n",
    "for year in range(2010,2020):\n",
    "        file_path = main_data_path + 'London/daten_wmm_london_' + str(year) + '.csv'\n",
    "        df_london_data_csv_temp = pd.read_csv(filepath_or_buffer=file_path,\n",
    "                header=0, sep=';',decimal='.'\n",
    "                ,names=[\n",
    "                'Jahr','Ges', 'Name','Club', 'Category', 'Runner_Number', 'Place_Gender', 'Place_Category','Place_Overall','Start_Time_of_day','Finish_Time', 'Race_Status','Last_Split'\n",
    "                ,'5K_Time_of_day','5K_Time','5K_Diff','5K_min_km','5K_kmh','10K_Time_of_day','10K_Time','10K_Diff','10K_min_km','10K_kmh','15K_Time_of_day','15K_Time','15K_Diff','15K_min_km','15K_kmh'\n",
    "                ,'20K_Time_of_day','20K_Time','20K_Diff','20K_min_km','20K_kmh','HK_Time_of_day','HK_Time','HK_Diff','HK_min_km','HK_kmh','25K_Time_of_day','25K_Time','25K_Diff','25K_min_km','25K_kmh'\n",
    "                ,'30K_Time_of_day','30K_Time','30K_Diff','30K_min_km','30K_kmh','35K_Time_of_day','35K_Time','35K_Diff','35K_min_km','35K_kmh','40K_Time_of_day','40K_Time','40K_Diff','40K_min_km','40K_kmh'\n",
    "                ,'FK_Time_of_day','FK_Time','FK_Diff','FK_min_km','FK_kmh'\n",
    "                ]\n",
    "        )\n",
    "        df_london_data_csv = df_london_data_csv.append(df_london_data_csv_temp, ignore_index=True)\n",
    "\n",
    "df_london_data_csv.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Nicht benötigte Spalten entfernen\n",
    "df_london_data = df_london_data_csv.drop(\n",
    "    columns=['Club', 'Category', 'Runner_Number','Place_Category','Place_Overall','Race_Status','Last_Split','5K_Time_of_day','5K_Diff','5K_min_km','5K_kmh','10K_Time_of_day','10K_Diff','10K_min_km','10K_kmh'\n",
    "                ,'15K_Time_of_day','15K_Diff','15K_min_km','15K_kmh','20K_Time_of_day','20K_Diff','20K_min_km','20K_kmh','HK_Time_of_day','HK_Diff','HK_min_km','HK_kmh','25K_Time_of_day','25K_Diff','25K_min_km','25K_kmh'\n",
    "                ,'30K_Time_of_day','30K_Diff','30K_min_km','30K_kmh','35K_Time_of_day','35K_Diff','35K_min_km','35K_kmh','40K_Time_of_day','40K_Diff','40K_min_km','40K_kmh','FK_Time_of_day','FK_Time','FK_Diff','FK_min_km','FK_kmh'\n",
    "    ])\n",
    "\n",
    "# Spalten hinzufügen\n",
    "df_london_data['Datum'] = None\n",
    "df_london_data['Nachname'] = None\n",
    "df_london_data['Ort'] = 'London'\n",
    "\n",
    "# Datum für für das jeweilige Jahr eintragen\n",
    "df_london_data['Datum'].mask(df_london_data['Jahr'] == 2019,'28.04.2019',inplace=True)\n",
    "df_london_data['Datum'].mask(df_london_data['Jahr'] == 2018,'22.04.2018',inplace=True)\n",
    "df_london_data['Datum'].mask(df_london_data['Jahr'] == 2017,'23.04.2017',inplace=True)\n",
    "df_london_data['Datum'].mask(df_london_data['Jahr'] == 2016,'24.04.2016',inplace=True)\n",
    "df_london_data['Datum'].mask(df_london_data['Jahr'] == 2015,'26.04.2015',inplace=True)\n",
    "df_london_data['Datum'].mask(df_london_data['Jahr'] == 2014,'13.04.2014',inplace=True)\n",
    "df_london_data['Datum'].mask(df_london_data['Jahr'] == 2013,'21.04.2013',inplace=True)\n",
    "df_london_data['Datum'].mask(df_london_data['Jahr'] == 2012,'22.04.2012',inplace=True)\n",
    "df_london_data['Datum'].mask(df_london_data['Jahr'] == 2011,'17.04.2011',inplace=True)\n",
    "df_london_data['Datum'].mask(df_london_data['Jahr'] == 2010,'25.04.2010',inplace=True)\n",
    "\n",
    "# Spalten umbenennen\n",
    "df_london_data = df_london_data.rename(\n",
    "    columns={'Ges':'Geschlecht','Place_Gender':'Platz','Finish_Time':'T_KM_FN','Name':'Vorname','Start_Time_of_day':'Startzeit',\n",
    "    '5K_Time':'T_KM_5','10K_Time':'T_KM_10','15K_Time':'T_KM_15','20K_Time':'T_KM_20','HK_Time':'T_KM_HM','25K_Time':'T_KM_25','30K_Time':'T_KM_30','35K_Time':'T_KM_35','40K_Time':'T_KM_40'})\n",
    "\n",
    "# Spalten umsortieren\n",
    "df_london_data = df_london_data[['Jahr','Ort','Geschlecht','Vorname','Nachname','Platz','Datum','Startzeit','T_KM_FN','T_KM_5','T_KM_10','T_KM_15','T_KM_20','T_KM_HM','T_KM_25','T_KM_30','T_KM_35','T_KM_40']]\n",
    "\n",
    "# Inhalt aus der ursprünglichen Spalte Name in Vorname und Nachname trennen\n",
    "for index, row in df_london_data.iterrows():\n",
    "    #print(row['Vorname'])\n",
    "    name_split_1 = row['Vorname'].split(',')\n",
    "    name_split_2 = name_split_1[1].split(' ')\n",
    "    name_split_2.pop(0)\n",
    "    name_split_2.pop(len(name_split_2)-1)\n",
    "    name_split_2 = ' '.join(name_split_2)\n",
    "    row['Vorname'] = name_split_2\n",
    "    row['Nachname'] = name_split_1[0]\n",
    "\n",
    "# Variable auf \"none\" setzen für spätere Verwendung\n",
    "name_split_1 = None\n",
    "name_split_2 = None\n",
    "\n",
    "df_london_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>\n",
    "<h1>4. New York-Marathon:</h1>\n",
    "<hr>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Temporäres Dateframe erzeugen\n",
    "df_newyork_data_csv = pd.DataFrame(pd.DataFrame(\n",
    "    columns=[\n",
    "        'Jahr','Ges','Start_Time_of_day','Name','Runner_Number','FK_Time','Pace_per_Mile','Place_Overall','Place_Gender','Age_Group','Place_Age_Group','Place_Age_Graded','Time_Age_Graded'\n",
    "        ,'Gun_Time','5K_Time','10K_Time','15K_Time','20K_Time','HK_Time','25K_Time','30K_Time','35K_Time','40K_Time'\n",
    "        ])\n",
    "    ,dtype=str)\n",
    "\n",
    "# Daten einlesen (Im Jahr 2012 fand kein Marathon statt)\n",
    "for year in [2007,2008,2009,2010,2011,2013,2014,2015,2016,2017,2018,2019]:\n",
    "        file_path = main_data_path + 'NYC/daten_wmm_nyc_' + str(year) + '.csv'\n",
    "        df_newyork_data_csv_temp = pd.read_csv(filepath_or_buffer=file_path,\n",
    "                header=0, sep=';',decimal='.'\n",
    "                ,names=[\n",
    "                'Jahr','Ges','Start_Time_of_day','Name','Runner_Number','FK_Time','Pace_per_Mile','Place_Overall','Place_Gender','Age_Group','Place_Age_Group','Place_Age_Graded','Time_Age_Graded'\n",
    "                ,'Gun_Time','5K_Time','10K_Time','15K_Time','20K_Time','HK_Time','25K_Time','30K_Time','35K_Time','40K_Time'\n",
    "                ]\n",
    "        )\n",
    "        df_newyork_data_csv = df_newyork_data_csv.append(df_newyork_data_csv_temp, ignore_index=True)\n",
    "\n",
    "df_newyork_data_csv.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Nicht benötigte Spalten entfernen\n",
    "df_newyork_data = df_newyork_data_csv.drop(\n",
    "    columns=['Runner_Number','Pace_per_Mile','Place_Overall','Age_Group','Place_Age_Group','Place_Age_Graded','Time_Age_Graded','Gun_Time'\n",
    "    ])\n",
    "\n",
    "# Spalten hinzufügen\n",
    "df_newyork_data['Datum'] = None\n",
    "df_newyork_data['Nachname'] = None\n",
    "df_newyork_data['Ort'] = 'NewYork'\n",
    "\n",
    "# Datum für für das jeweilige Jahr eintragen\n",
    "df_newyork_data['Datum'].mask(df_newyork_data['Jahr'] == 2019,'03.11.2019',inplace=True)\n",
    "df_newyork_data['Datum'].mask(df_newyork_data['Jahr'] == 2018,'04.11.2018',inplace=True)\n",
    "df_newyork_data['Datum'].mask(df_newyork_data['Jahr'] == 2017,'05.11.2017',inplace=True)\n",
    "df_newyork_data['Datum'].mask(df_newyork_data['Jahr'] == 2016,'06.11.2016',inplace=True)\n",
    "df_newyork_data['Datum'].mask(df_newyork_data['Jahr'] == 2015,'01.11.2015',inplace=True)\n",
    "df_newyork_data['Datum'].mask(df_newyork_data['Jahr'] == 2014,'02.11.2014',inplace=True)\n",
    "df_newyork_data['Datum'].mask(df_newyork_data['Jahr'] == 2013,'03.11.2013',inplace=True)\n",
    "df_newyork_data['Datum'].mask(df_newyork_data['Jahr'] == 2011,'06.11.2011',inplace=True)\n",
    "df_newyork_data['Datum'].mask(df_newyork_data['Jahr'] == 2010,'07.11.2010',inplace=True)\n",
    "df_newyork_data['Datum'].mask(df_newyork_data['Jahr'] == 2009,'01.11.2009',inplace=True)\n",
    "df_newyork_data['Datum'].mask(df_newyork_data['Jahr'] == 2008,'02.11.2008',inplace=True)\n",
    "df_newyork_data['Datum'].mask(df_newyork_data['Jahr'] == 2007,'04.11.2007',inplace=True)\n",
    "\n",
    "# Spalten umbenennen\n",
    "df_newyork_data = df_newyork_data.rename(\n",
    "    columns={'Ges':'Geschlecht','Place_Gender':'Platz','FK_Time':'T_KM_FN','Name':'Vorname','Start_Time_of_day':'Startzeit',\n",
    "    '5K_Time':'T_KM_5','10K_Time':'T_KM_10','15K_Time':'T_KM_15','20K_Time':'T_KM_20','HK_Time':'T_KM_HM','25K_Time':'T_KM_25','30K_Time':'T_KM_30','35K_Time':'T_KM_35','40K_Time':'T_KM_40'})\n",
    "\n",
    "# Uhrzeit korrigieren: 2:00PM zu 12:00PM (Fehler ist beim abziehen der Daten entstanden)\n",
    "df_newyork_data['Startzeit'].mask(df_newyork_data['Jahr'] == 2018,'12:00PM',inplace=True)\n",
    "\n",
    "# Spalten umsortieren\n",
    "df_newyork_data = df_newyork_data[['Jahr','Ort','Geschlecht','Vorname','Nachname','Platz','Datum','Startzeit','T_KM_FN','T_KM_5','T_KM_10','T_KM_15','T_KM_20','T_KM_HM','T_KM_25','T_KM_30','T_KM_35','T_KM_40']]\n",
    "\n",
    "# Inhalt aus der ursprünglichen Spalte Name in Vorname und Nachname trennen\n",
    "for index, row in df_newyork_data.iterrows():\n",
    "    #print(row['Vorname'])\n",
    "    name_split = row['Vorname'].split(' ')\n",
    "    name_vname = name_split[0]\n",
    "    name_split.pop(0)\n",
    "    name_nname = ' '.join(name_split)\n",
    "    row['Vorname'] = name_vname\n",
    "    row['Nachname'] = name_nname\n",
    "    #start_zeit = row['Startzeit']\n",
    "    #row['Startzeit'] = start_zeit[:-2]\n",
    "\n",
    "# Variable auf \"none\" setzen für spätere Verwendung\n",
    "name_split = None\n",
    "\n",
    "df_newyork_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>\n",
    "<h1>5. Tokyo-Marathon:</h1>\n",
    "<hr>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Temporäres Dateframe erzeugen (für die Jahre 2007 bis 2014)\n",
    "\n",
    "df_tokyo_data_csv_1 = pd.DataFrame(pd.DataFrame(\n",
    "    columns=[\n",
    "        'Jahr','Ges','Name','Number','Time','Time_Chip ','Place','5K_Time','10K_Time','15K_Time','20K_Time','HK_Time','25K_Time','30K_Time','35K_Time','40K_Time','FK_Time'\n",
    "        ])\n",
    "    ,dtype=str)\n",
    "\n",
    "# Temporäres Dateframe erzeugen (für die Jahre 2015 bis 2019)\n",
    "df_tokyo_data_csv_2 = pd.DataFrame(pd.DataFrame(\n",
    "    columns=[\n",
    "        'Jahr','Ges','Place_Overall','Number_Card','Name','Age_Group','Place_Age_Group','Place_Gender','Time_net','Time_gross','5K_Time','10K_Time','15K_Time','20K_Time'\n",
    "        ,'HK_Time','25K_Time','30K_Time','35K_Time','40K_Time','FK_Time'\n",
    "        ])\n",
    "    ,dtype=str)\n",
    "\n",
    "# Daten einlesen (2007 bis 2014)\n",
    "for year in range(2007,2015):\n",
    "        file_path = main_data_path + 'Tokyo/daten_wmm_tokyo_' + str(year) + '.csv'\n",
    "        df_tokyo_data_csv_temp_1 = pd.read_csv(filepath_or_buffer=file_path,\n",
    "                header=0, sep=';',decimal='.'\n",
    "                ,names=[\n",
    "                    'Jahr','Ges','Name','Number','Time','Time_Chip ','Place','5K_Time','10K_Time','15K_Time','20K_Time','HK_Time','25K_Time','30K_Time','35K_Time','40K_Time','FK_Time'\n",
    "                ]\n",
    "        )\n",
    "        df_tokyo_data_csv_1 = df_tokyo_data_csv_1.append(df_tokyo_data_csv_temp_1, ignore_index=True)\n",
    "\n",
    "# Daten einlesen (2015 bis 2019)\n",
    "for year in range(2015,2020):\n",
    "        file_path = main_data_path + 'Tokyo/daten_wmm_tokyo_' + str(year) + '.csv'\n",
    "        df_tokyo_data_csv_temp_2 = pd.read_csv(filepath_or_buffer=file_path,\n",
    "                header=0, sep=';',decimal='.'\n",
    "                ,names=[\n",
    "                    'Jahr','Ges','Place_Overall','Number_Card','Name','Age_Group','Place_Age_Group','Place_Gender','Time_net','Time_gross','5K_Time','10K_Time','15K_Time'\n",
    "                    ,'20K_Time','HK_Time','25K_Time','30K_Time','35K_Time','40K_Time','FK_Time'\n",
    "                ]\n",
    "        )\n",
    "        df_tokyo_data_csv_2 = df_tokyo_data_csv_2.append(df_tokyo_data_csv_temp_2, ignore_index=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_tokyo_data_csv_1.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Nicht benötigte Spalten entfernen (Jahr 2007 bis 2014)\n",
    "df_tokyo_data_1 = df_tokyo_data_csv_1.drop(\n",
    "    columns=['Time', 'Time_Chip '\n",
    "    ])\n",
    "\n",
    "# Spalten hinzufügen (Jahr 2007 bis 2014)\n",
    "df_tokyo_data_1['Datum'] = None\n",
    "df_tokyo_data_1['Startzeit'] = None\n",
    "df_tokyo_data_1['Ort'] = 'Toyko'\n",
    "\n",
    "# Spalten umbenennen (Jahr 2007 bis 2014)\n",
    "df_tokyo_data_1 = df_tokyo_data_1.rename(\n",
    "    columns={'Ges':'Geschlecht','Place':'Platz','FK_Time':'T_KM_FN','Name':'Vorname','Number':'Nachname','FK_Time':'T_KM_FN',\n",
    "    '5K_Time':'T_KM_5','10K_Time':'T_KM_10','15K_Time':'T_KM_15','20K_Time':'T_KM_20','HK_Time':'T_KM_HM','25K_Time':'T_KM_25','30K_Time':'T_KM_30','35K_Time':'T_KM_35','40K_Time':'T_KM_40'})\n",
    "\n",
    "# Spalten umsortieren (Jahr 2007 bis 2014)\n",
    "df_tokyo_data_1 = df_tokyo_data_1[['Jahr','Ort','Geschlecht','Vorname','Nachname','Platz','Datum','Startzeit','T_KM_FN','T_KM_5','T_KM_10','T_KM_15','T_KM_20','T_KM_HM','T_KM_25','T_KM_30','T_KM_35','T_KM_40']]\n",
    "\n",
    "df_tokyo_data_1.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_tokyo_data_csv_2.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Nicht benötigte Spalten entfernen (Jahr 2015 bis 2019)\n",
    "df_tokyo_data_2 = df_tokyo_data_csv_2.drop(\n",
    "    columns=['Place_Overall','Age_Group','Place_Age_Group','Time_net','Time_gross'\n",
    "    ])\n",
    "# Spalten hinzufügen (Jahr 2015 bis 2019)\n",
    "df_tokyo_data_2['Datum'] = None\n",
    "df_tokyo_data_2['Startzeit'] = None\n",
    "df_tokyo_data_2['Ort'] = 'Toyko'\n",
    "\n",
    "# Spalten umbenennen (Jahr 2015 bis 2019)\n",
    "df_tokyo_data_2 = df_tokyo_data_2.rename(\n",
    "    columns={'Ges':'Geschlecht','Place_Gender':'Platz','FK_Time':'T_KM_FN','Name':'Vorname','Number_Card':'Nachname','FK_Time':'T_KM_FN',\n",
    "    '5K_Time':'T_KM_5','10K_Time':'T_KM_10','15K_Time':'T_KM_15','20K_Time':'T_KM_20','HK_Time':'T_KM_HM','25K_Time':'T_KM_25','30K_Time':'T_KM_30','35K_Time':'T_KM_35','40K_Time':'T_KM_40'})\n",
    "\n",
    "# Spalten umsortieren (Jahr 2015 bis 2019)\n",
    "df_tokyo_data_2 = df_tokyo_data_2[['Jahr','Ort','Geschlecht','Vorname','Nachname','Platz','Datum','Startzeit','T_KM_FN','T_KM_5','T_KM_10','T_KM_15','T_KM_20','T_KM_HM','T_KM_25','T_KM_30','T_KM_35','T_KM_40']]\n",
    "\n",
    "df_tokyo_data_2.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Datensätze aus den Jahren 2007 bis 2014 mit den Datensätzen aus den Jahren 2015 bis 2019 zusammenführen\n",
    "df_tokyo_data = pd.concat([df_tokyo_data_1,df_tokyo_data_2], ignore_index=True)\n",
    "\n",
    "# Datum für für das jeweilige Jahr eintragen (2007 bis 2019)\n",
    "df_tokyo_data['Datum'].mask(df_tokyo_data['Jahr'] == 2019,'03.03.2019',inplace=True)\n",
    "df_tokyo_data['Datum'].mask(df_tokyo_data['Jahr'] == 2018,'25.02.2018',inplace=True)\n",
    "df_tokyo_data['Datum'].mask(df_tokyo_data['Jahr'] == 2017,'26.02.2017',inplace=True)\n",
    "df_tokyo_data['Datum'].mask(df_tokyo_data['Jahr'] == 2016,'28.02.2016',inplace=True)\n",
    "df_tokyo_data['Datum'].mask(df_tokyo_data['Jahr'] == 2015,'22.02.2015',inplace=True)\n",
    "df_tokyo_data['Datum'].mask(df_tokyo_data['Jahr'] == 2014,'23.02.2014',inplace=True)\n",
    "df_tokyo_data['Datum'].mask(df_tokyo_data['Jahr'] == 2013,'24.02.2013',inplace=True)\n",
    "df_tokyo_data['Datum'].mask(df_tokyo_data['Jahr'] == 2012,'26.02.2012',inplace=True)\n",
    "df_tokyo_data['Datum'].mask(df_tokyo_data['Jahr'] == 2011,'27.02.2011',inplace=True)\n",
    "df_tokyo_data['Datum'].mask(df_tokyo_data['Jahr'] == 2010,'28.02.2010',inplace=True)\n",
    "df_tokyo_data['Datum'].mask(df_tokyo_data['Jahr'] == 2009,'22.03.2009',inplace=True)\n",
    "df_tokyo_data['Datum'].mask(df_tokyo_data['Jahr'] == 2008,'17.02.2008',inplace=True)\n",
    "df_tokyo_data['Datum'].mask(df_tokyo_data['Jahr'] == 2007,'18.02.2007',inplace=True)\n",
    "\n",
    "# Inhalt aus der ursprünglichen Spalte Name in Vorname und Nachname trennen\n",
    "for index, row in df_tokyo_data.iterrows():\n",
    "    #print(row['Vorname'])\n",
    "    name_split = row['Vorname'].split(' ')\n",
    "    if len(name_split) > 2:\n",
    "        row['Nachname'] = name_split[1] + ' ' + name_split[2]\n",
    "    else:\n",
    "        row['Nachname'] = name_split[1]\n",
    "\n",
    "    row['Vorname'] = name_split[0]\n",
    "    \n",
    "# Variable auf \"none\" setzen für spätere Verwendung\n",
    "name_split = None\n",
    "\n",
    "df_tokyo_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>\n",
    "<h1>Alle eingelesenen und harmonisierten Datensätze zusammenführen</h1>\n",
    "<hr>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Alle Datensätze zusammenführen\n",
    "df_wmm_data_all = pd.concat([df_berlin_data,df_chicago_data,df_london_data,df_newyork_data,df_tokyo_data], ignore_index=True)\n",
    "df_wmm_data_all.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Alle Datensätze in eine CSV-Datei speichern.\n",
    "file_name = main_data_path + \"wmm_data/daten_wmm_all.csv\"\n",
    "df_wmm_data_all.to_csv(file_name, sep=';', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f2ef7edd20578ec9754dace98dfc677349137fe4e064a9a45fddd79cef6b16b"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}